{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### import\n",
    "import arcpy\n",
    "import os\n",
    "from sys import argv\n",
    "from geopy.geocoders import GoogleV3\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "\n",
    "### input parameter\n",
    "folder=arcpy.GetParameterAsText(0)\n",
    "google_api_key=arcpy.GetParameterAsText(1)\n",
    "warm_bank_list_path=arcpy.GetParameterAsText(2)\n",
    "MSOA=arcpy.GetParameterAsText(3)\n",
    "popcentroids=arcpy.GetParameterAsText(4)\n",
    "\n",
    "\n",
    "### environment\n",
    "arcpy.env.workspace = folder\n",
    "arcpy.env.overwriteOutput = True\n",
    "\n",
    "\n",
    "### define functions\n",
    "def list_to_point(warm_bank_list_path,google_api_key):\n",
    "    # Get the warm bank list\n",
    "    warm_bank_list=pd.read_excel(warm_bank_list_path)\n",
    "    \n",
    "    # Create Google Geocoding\n",
    "    geolocator = GoogleV3(google_api_key)\n",
    "    def geocode(location):\n",
    "        location = geolocator.geocode(location)\n",
    "        if location is None:\n",
    "            return None, None\n",
    "        return location.latitude, location.longitude\n",
    "    # Convert the postcode to latitude and longitude\n",
    "    warm_bank_list = warm_bank_list.dropna(subset=['Organisation Postcode'])\n",
    "    warm_bank_list['latitude'], warm_bank_list['longitude'] = zip(*warm_bank_list['Organisation Postcode'].apply(geocode))\n",
    "    warm_bank_list['latitude'] = warm_bank_list['latitude'].fillna('UNKNOWN')\n",
    "    warm_bank_list['longitude'] = warm_bank_list['longitude'].fillna('UNKNOWN')\n",
    "    # Filter out the points that are not in the UK\n",
    "    warm_bank_list = warm_bank_list[warm_bank_list['latitude'] != 'UNKNOWN']\n",
    "    warm_bank_list = warm_bank_list[warm_bank_list['longitude'] <= 2]\n",
    "    warm_bank_list = warm_bank_list[warm_bank_list['longitude'] >= -7]\n",
    "    warm_bank_list = warm_bank_list[warm_bank_list['latitude'] >= 48]\n",
    "    warm_bank_list = warm_bank_list[warm_bank_list['latitude'] <= 60]\n",
    "    # Output the csv file\n",
    "    london_wb_geom = gpd.GeoDataFrame(warm_bank_list,geometry=gpd.points_from_xy(warm_bank_list.longitude, warm_bank_list.latitude))\n",
    "    london_wb_geom.crs = {\"init\": \"epsg:4326\"}\n",
    "    london_wb_geom = london_wb_geom.to_crs(epsg=27700)\n",
    "    london_wb_geom = pd.DataFrame(london_wb_geom)\n",
    "    london_wb_geom.to_csv(fr\"{folder}\\warm_bank_list.csv\", index=False)\n",
    "    # Convert the csv file to a point feature class\n",
    "    arcpy.CreateFileGDB_management(folder, 'points.gdb')\n",
    "    arcpy.management.XYTableToPoint(fr\"{folder}\\warm_bank_list.csv\", fr\"{folder}\\points.gdb\\warm_bank\", 'longitude', 'latitude', coordinate_system='4326')\n",
    "    \n",
    "\n",
    "def split_by_count(input_fc, count=999):\n",
    "    # Get a list of OBJECTIDs from the input feature class\n",
    "    objectids = [row[0] for row in arcpy.da.SearchCursor(input_fc, 'OBJECTID')]\n",
    "    total_count = len(objectids)\n",
    "    # If the total count is less than or equal to the specified count, exit the function\n",
    "    if total_count <= count:\n",
    "        return\n",
    "    # Create a feature layer from the input feature class\n",
    "    arcpy.management.MakeFeatureLayer(input_fc, \"temp_layer\")\n",
    "    # Retrieve the directory and the name of the input feature class\n",
    "    folder_path, fc_name = os.path.split(input_fc)\n",
    "    fc_name_noext = os.path.splitext(fc_name)[0]  # Get the name without the extension\n",
    "    start_index = 0\n",
    "    chunk_num = 1\n",
    "    while start_index < total_count:\n",
    "        end_index = start_index + count\n",
    "        if end_index > total_count:\n",
    "            end_index = total_count\n",
    "        current_ids = objectids[start_index:end_index]\n",
    "        sql_query = \"OBJECTID IN ({})\".format(','.join(map(str, current_ids)))\n",
    "        # Select the subset of features\n",
    "        arcpy.management.SelectLayerByAttribute(\"temp_layer\", \"NEW_SELECTION\", sql_query)\n",
    "        # Name for the output feature class\n",
    "        output_fc = os.path.join(folder_path, f\"{fc_name_noext}_{chunk_num}\")\n",
    "        # Export the selected features to a new feature class\n",
    "        arcpy.management.CopyFeatures(\"temp_layer\", output_fc)\n",
    "        start_index = end_index\n",
    "        chunk_num += 1\n",
    "    # Remove the original feature class and the temporary feature layer\n",
    "    arcpy.management.Delete(input_fc)\n",
    "    arcpy.management.Delete(\"temp_layer\")\n",
    "\n",
    "def FeatureClassGenerator(workspace, wild_card, feature_type, recursive) :\n",
    "    with arcpy.EnvManager(workspace = workspace):\n",
    "        dataset_list = [\"\"]\n",
    "        if recursive:\n",
    "            datasets = arcpy.ListDatasets()\n",
    "            dataset_list.extend(datasets)\n",
    "            for dataset in dataset_list:\n",
    "                featureclasses = arcpy.ListFeatureClasses(wild_card, feature_type, dataset)\n",
    "                for fc in featureclasses:\n",
    "                    yield os.path.join(workspace, dataset, fc), fc\n",
    "\n",
    "def get_latest_feature_dataset_in_gdb(gdb_path):\n",
    "    arcpy.env.workspace = gdb_path\n",
    "    feature_datasets = arcpy.ListDatasets()\n",
    "    if not feature_datasets:\n",
    "        return None\n",
    "    return feature_datasets[-1]\n",
    "                    \n",
    "def analysis(_folder_):\n",
    "    # To allow overwriting outputs change overwriteOutput option to True.\n",
    "    arcpy.env.overwriteOutput = True\n",
    "    Network_Data_Source = \"https://www.arcgis.com/\"\n",
    "    _points_gdb = fr\"{folder}\\points.gdb\"\n",
    "    _folder_ = fr\"{folder}\"\n",
    "    _sa_gdb = arcpy.management.CreateFileGDB(out_folder_path=_folder_, out_name=\"sa\")[0]\n",
    "    _working_gdb = arcpy.management.CreateFileGDB(out_folder_path=_folder_, out_name=\"working\")[0]\n",
    "    for point, names in FeatureClassGenerator(_points_gdb, \"\", \"\", \"NOT_RECURSIVE\"):\n",
    "        # Process: Make Service Area Analysis Layer (Make Service Area Analysis Layer) (na)\n",
    "        arcpy.env.workspace = fr\"{folder}\\working.gdb\"\n",
    "        Service_Area_layer = arcpy.na.MakeServiceAreaAnalysisLayer(network_data_source=Network_Data_Source, travel_mode=\"Walking Time\", cutoffs=[30], time_of_day=\"2023/9/1\", polygon_detail=\"STANDARD\", geometry_at_overlaps=\"OVERLAP\", polygon_trim_distance=\"50 Meters\", geometry_at_cutoffs=\"DISKS\")[0]     \n",
    "        # Process: Add Facilities (Add Locations) (na)\n",
    "        Service_Area_layer_with_names = arcpy.na.AddLocations(in_network_analysis_layer=Service_Area_layer, sub_layer=\"Facilities\", in_table=point)[0]\n",
    "        # Check if point is empty\n",
    "        feature_count = int(arcpy.GetCount_management(point).getOutput(0))\n",
    "        if feature_count == 0:\n",
    "            # Create an empty polygon feature class named sa_{names} with two float fields\n",
    "            output_fc_path = fr\"{folder}\\sa.gdb\\sa_{names}\"\n",
    "            arcpy.CreateFeatureclass_management(\n",
    "                out_path=_sa_gdb,\n",
    "                out_name=f\"sa_{names}\",\n",
    "                geometry_type=\"POLYGON\"\n",
    "            )\n",
    "            arcpy.AddField_management(output_fc_path, \"FromBreak\", \"FLOAT\")\n",
    "            arcpy.AddField_management(output_fc_path, \"ToBreak\", \"FLOAT\")\n",
    "        else:\n",
    "            # Process: Solve (Solve) (na)\n",
    "            Service_Area_result, Solve_Succeeded = arcpy.na.Solve(in_network_analysis_layer=Service_Area_layer_with_names)\n",
    "            # Process: Select_Data (Select Data)      \n",
    "            def find_and_export_sa_features(gdb_path, feature_dataset_name, output_folder):\n",
    "                arcpy.env.workspace = os.path.join(gdb_path, feature_dataset_name)\n",
    "                feature_classes = arcpy.ListFeatureClasses()\n",
    "                sa_features = [fc for fc in feature_classes if 'SAPolygons' in fc]\n",
    "                for sa_feature in sa_features:\n",
    "                    new_name = fr\"sa_{names}\"\n",
    "                    output_path = os.path.join(output_folder, new_name)\n",
    "                    arcpy.CopyFeatures_management(sa_feature, output_path)\n",
    "            latest_dataset = get_latest_feature_dataset_in_gdb(_working_gdb)\n",
    "            find_and_export_sa_features(_working_gdb, latest_dataset, _sa_gdb)\n",
    "            arcpy.Delete_management(os.path.join(_working_gdb, latest_dataset))\n",
    "\n",
    "def get_common_name(fcs):\n",
    "    if len(fcs) >= 2:\n",
    "        return os.path.commonprefix(fcs).rstrip('_')\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def group_feature_classes_by_field(gdb):\n",
    "    arcpy.env.workspace = gdb\n",
    "    grouped_fcs = {}\n",
    "    # List all feature classes in the geodatabase\n",
    "    fcs = arcpy.ListFeatureClasses()\n",
    "    # Iterate over feature classes and group by the field between underscores\n",
    "    for fc in fcs:\n",
    "        parts = fc.split('_')\n",
    "        if len(parts) > 2:\n",
    "            key_field = parts[2]\n",
    "            if key_field not in grouped_fcs:\n",
    "                grouped_fcs[key_field] = []\n",
    "            grouped_fcs[key_field].append(fc)\n",
    "    return grouped_fcs\n",
    "\n",
    "def merge_and_rename_feature_classes_by_group(gdb):\n",
    "    grouped_fcs = group_feature_classes_by_field(gdb)\n",
    "    for key, fcs in grouped_fcs.items():\n",
    "        common_name = get_common_name(fcs)\n",
    "        if common_name:\n",
    "            # Merge the feature classes\n",
    "            temp_output_fc = f\"{common_name}_merged\"\n",
    "            arcpy.Merge_management(fcs, temp_output_fc)\n",
    "            # Rename the merged feature class by removing everything after the last underscore\n",
    "            final_name = \"_\".join(temp_output_fc.split('_')[:-1])\n",
    "            arcpy.Rename_management(temp_output_fc, final_name)\n",
    "            # Delete the source feature classes\n",
    "            for fc in fcs:\n",
    "                arcpy.Delete_management(fc)\n",
    "\n",
    "def accessibility_count(MSOA, popcentroids, sa_warm_bank):\n",
    "    _working_gdb=arcpy.management.CreateFileGDB(out_folder_path=folder, out_name=\"working\")[0]\n",
    "    _result_gdb=arcpy.management.CreateFileGDB(out_folder_path=folder, out_name=\"result\")[0]\n",
    "    access_count = fr\"{folder}\\working.gdb\\access_count\"\n",
    "    access_count_MSOA = fr\"{folder}\\working.gdb\\access_count_MSOA\"\n",
    "    # Process: Spatial Join (Spatial Join) (analysis)\n",
    "    arcpy.analysis.SpatialJoin(target_features=popcentroids, join_features=sa_warm_bank, out_feature_class=access_count, \n",
    "                               search_radius=\"50 Meters\")\n",
    "    # Field mapping\n",
    "    field_mappings = arcpy.FieldMappings()\n",
    "    # Field map for MSOA21CD\n",
    "    field_map_MSOA21CD = arcpy.FieldMap()\n",
    "    field_map_MSOA21CD.addInputField(MSOA, \"MSOA21CD\")\n",
    "    field_mappings.addFieldMap(field_map_MSOA21CD)\n",
    "    # Field map for MSOA21NM\n",
    "    field_map_MSOA21NM = arcpy.FieldMap()\n",
    "    field_map_MSOA21NM.addInputField(MSOA, \"MSOA21NM\")\n",
    "    field_mappings.addFieldMap(field_map_MSOA21NM)\n",
    "    # Field map for Count\n",
    "    join_count_field_map = arcpy.FieldMap()\n",
    "    join_count_field_map.addInputField(access_count, \"Join_Count\")\n",
    "    join_count_field = join_count_field_map.outputField\n",
    "    join_count_field.name = \"Count\"\n",
    "    join_count_field.aliasName = \"Count\"\n",
    "    join_count_field_map.outputField = join_count_field\n",
    "    field_mappings.addFieldMap(join_count_field_map)\n",
    "    # Process: Spatial Join (2) (Spatial Join) (analysis)\n",
    "    arcpy.analysis.SpatialJoin(target_features=MSOA, join_features=access_count, out_feature_class=access_count_MSOA, field_mapping=field_mappings)\n",
    "    # Process: Delete Field (Delete Field) (management)\n",
    "    field_mappings_output = arcpy.FieldMappings()\n",
    "    field_map_msoa21cd = arcpy.FieldMap()\n",
    "    field_map_msoa21cd.addInputField(access_count_MSOA, \"MSOA21CD\")\n",
    "    field_mappings_output.addFieldMap(field_map_msoa21cd)\n",
    "    field_map_msoa21nm = arcpy.FieldMap()\n",
    "    field_map_msoa21nm.addInputField(access_count_MSOA, \"MSOA21NM\")\n",
    "    field_mappings_output.addFieldMap(field_map_msoa21nm)\n",
    "    field_map_count = arcpy.FieldMap()\n",
    "    field_map_count.addInputField(access_count_MSOA, \"Count\")\n",
    "    field_mappings_output.addFieldMap(field_map_count)\n",
    "    arcpy.conversion.FeatureClassToFeatureClass(in_features=access_count_MSOA,out_path=_result_gdb,out_name='accessibility', field_mapping=field_mappings_output)    \n",
    "    # Delete the working geodatabase\n",
    "    arcpy.Delete_management(os.path.join(_working_gdb))\n",
    "\n",
    "\n",
    "### run\n",
    "with arcpy.EnvManager(outputCoordinateSystem=\"PROJCS[\\\"British_National_Grid\\\",GEOGCS[\\\"GCS_OSGB_1936\\\",DATUM[\\\"D_OSGB_1936\\\",SPHEROID[\\\"Airy_1830\\\",6377563.396,299.3249646]],PRIMEM[\\\"Greenwich\\\",0.0],UNIT[\\\"Degree\\\",0.0174532925199433]],PROJECTION[\\\"Transverse_Mercator\\\"],PARAMETER[\\\"False_Easting\\\",400000.0],PARAMETER[\\\"False_Northing\\\",-100000.0],PARAMETER[\\\"Central_Meridian\\\",-2.0],PARAMETER[\\\"Scale_Factor\\\",0.9996012717],PARAMETER[\\\"Latitude_Of_Origin\\\",49.0],UNIT[\\\"Meter\\\",1.0]]\", scratchWorkspace=folder, workspace=folder):\n",
    "    # run\n",
    "    list_to_point(warm_bank_list_path, google_api_key)\n",
    "    split_by_count(fr\"{folder}\\points.gdb\\warm_bank\", count=999)\n",
    "    analysis(folder)\n",
    "    merge_and_rename_feature_classes_by_group(fr\"{folder}\\sa.gdb\")\n",
    "    accessibility_count(MSOA, popcentroids, sa_warm_bank=fr\"{folder}\\sa.gdb\\sa_warm_bank\")\n",
    "    arcpy.SetParameter(5, True)\n",
    "    arcpy.AddMessage(\"Success!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ArcGISPro",
   "language": "Python",
   "name": "python3"
  },
  "language_info": {
   "file_extension": ".py",
   "name": "python",
   "version": "3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
